# Intro to Machine Learning
This course is estimated to last 3 hours, builds on Python, and prepares for the following courses:
- [Machine Learning Explainability](https://www.kaggle.com/learn/machine-learning-explainability)
- [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)
- [Intro to Deep Learning](https://www.kaggle.com/learn/intro-to-deep-learning)

## [Lesson 1: How Models Work](https://www.kaggle.com/code/dansbecker/how-models-work)
### Introduction
Machine Learning is about identifying patterns in order to make predictions. An example modle that does this are the **decision trees**. A very basic example would be to check a certain variable (e.g., the number of bedrooms in a house) to classify the inputs (e.g., a house) into different categories (e.g., price ranges).

The process of finding out the patters in the data is called ***fitting*** or ***training***. The data used to *fit* the model is called *training data*. Once the model has been fit, you can use it with new data to do *predictions*.

### Improving the Decision Tree
You can add more layers to your decision trees to further classify the already classified inputs. For example, after checking the number of bedrooms, you could check the square meters to get a finer prediction of the market price of a house. Each layer is called a **split** and the more of them a decision tree has, the *deeper* it is. The bottom layers with the predicted price for a given house are called **leafs**.

## [Lesson 2: Bassic Data Exploration](https://www.kaggle.com/code/dansbecker/basic-data-exploration)
TODO

## [Lesson 3: Your First Machine Learning Model](https://www.kaggle.com/code/dansbecker/your-first-machine-learning-model)
TODO

## [Lesson 4: Model Validation](https://www.kaggle.com/code/dansbecker/model-validation)
TODO

## [Lesson 5: Underfitting and Overfitting](https://www.kaggle.com/code/dansbecker/underfitting-and-overfitting)
TODO

## [Lesson 6: Random Forests](https://www.kaggle.com/code/dansbecker/random-forests)
TODO

## [Lesson 7: Machine Learning Competitions](https://www.kaggle.com/code/alexisbcook/machine-learning-competitions)
TODO
